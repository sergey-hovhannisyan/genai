{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from torchvision import transforms\n","from torchvision.datasets import FashionMNIST\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{},"source":["### Dataset"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","trainset = FashionMNIST(root='./data', train=True, transform=transform, download=True)\n","testset = FashionMNIST(root='./data', train=False, transform=transform, download=True)"]},{"cell_type":"markdown","metadata":{},"source":["### Variational Autoencoder"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self) -> None: \n","        super(Encoder, self).__init__()\n","\n","class Decoder(nn.Module):\n","    def __init__(self) -> None: \n","        super(Decoder, self).__init__()\n","        \n","class LatentSpace(nn.Module):\n","    def __init__(self) -> None: \n","        super(LatentSpace, self).__init__()\n","        \n","class VAE(nn.Module):\n","    def __init__(self, encoder, decoder, latentspace) -> None: \n","        super(VAE, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.latentspace = latentspace\n","        \n","    def forward(self, input):\n","        ..."]}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":2}
